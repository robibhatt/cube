experiment_type: TrainMLP
trainer_config:
    trainer_type: Trainer
    model_config:
        model_type: MLP
        input_dim: 16
        output_dim: 1
        hidden_dims:
        - 128
        - 128
        activation: relu
        start_activation: false
        end_activation: false
        mup: true
        bias: true
    optimizer_config:
        optimizer_type: sgd
        lr: 0.005
        mup: true
        weight_decay: 0.0
    cube_distribution_config:
        distribution_type: CubeDistribution
        input_dim: 16
        indices_list:
        - [0]
        - [0, 1]
        - [0, 1, 2]
        - [0, 1, 2, 3]
        - [0, 1, 2, 3, 4]
        - [0, 1, 2, 3, 4, 5]
        - [0, 1, 2, 3, 4, 5, 6]
        - [0, 1, 2, 3, 4, 5, 6, 7]
        - [0, 1, 2, 3, 4, 5, 6, 7, 8]
        - [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
        - [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        - [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
        weights:
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        - 1.0
        normalize: true
        noise_mean: 0.0
        noise_std: 0.1
    train_size: 1024
    test_size: 1024
    batch_size: 128
    epochs: 3
    use_full_batch: false
    weight_decay_l1: 0.0004
home_directory: experiment_runs/test/17
seed: 12321245
run_parallel: false
